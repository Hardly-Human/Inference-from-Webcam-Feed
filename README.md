# Inference-from-Webcam-Feed
A Neural network drawing Inference from real-time webcam feed. 

- This Project Involves capturing Images from live webcam feed and training them on a MobileNet model implemented in __TensorflowJS__.
- A DNN is added at the bottom layers of MobileNet model to perform __Transfer Learning__ inorder to implement _multi-class classification_ with Rock,paper and scissors data. 
- This project uses a __webcam.js__ file Open-sourced by __GOOGLE__ to simplify the operations handling webcam feed from browsers.

### ** Note : The Learning Algorithms Quality of Inference is based upon the Quality of Data fed to Algorithm. Evidently less data fed to Algorithm leads to Poor Quality of predictions. 

## Instructions to Use:
- Clone this repository [Inference-from-Webcam-Feed](https://github.com/Hardly-Human/Inference-from-Webcam-Feed.git) to your local computer.
- open __Inference from Webcam.html__ file. (__Use Chrome Browser for best view__)


- __Feeding Data:__

<pre>
 <img src = "https://raw.githubusercontent.com/Hardly-Human/Inference-from-Webcam-Feed/master/paper.png" width = "600" height= "400">     <img src = "https://raw.githubusercontent.com/Hardly-Human/Inference-from-Webcam-Feed/master/rock.png" width = "600" height= "400">     <img src = "https://raw.githubusercontent.com/Hardly-Human/Inference-from-Webcam-Feed/master/scissors.png" width = "600" height= "400">
</pre>


- __Predictions:__

  <img src = "https://raw.githubusercontent.com/Hardly-Human/Inference-from-Webcam-Feed/master/prediction.png" width = "600" height= "400">

